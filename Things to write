hashtable using linear data structure done
string buffer using list 
mergesort (top down and bottom up)
quicksort
(have a look)
tree and basic actions, insertion(trivial), deletion(BST two cases), self-balancing(insertion O(1), deletion O(log n) for AVL tree)

heaps(max heap: parent node larger than children, find max: O(1), delete O(logn), insertion O(logn))
heapsort: worst O(nlogn), in place

look up python dictionary speed
n-ary trees (children <= n), 
trie (for saving strings efficiently)
3 ways of representing a graph
(prepare for)
introduction
comparison of different sorting algorithms

Remember:
Debug the code at the end 

Introduction:
I am a second year PhD student at Harvard. I am applying for the Google software engineer intern for research role. My research is on computational sensing. Especially I am combining optics and computation to build small sensing platforms to measure depth and other information. My final research goal is to set up a joint optical and computational framework, so that I could conduct end-to-end training on this system. My latest project is on building a depth sensor inspired by the eyes' of jumping spiders, and train its optical parameters to improve the performance. I used to TensorFlow to do it.


Another version:
In general, my research is on computational sensing. Currently, I am combining optics and computation to measure depth and other scene information using small sensing platform and little power. My final goal is to do an end-to-end training of the entire optical system, which includes both the optical setups and inference algorithms. 

 

My last project is on building an unactuated, monocular depth and motion sensor. We call it the focal flow sensor. We showed that by taking differential defocus measurement, we could form enough linear constraints to solve for local patch based depth and 3D-velocity. Differential defocus means taking images with very small defocus change.  

 

Then, we rewrite the focal flow algorithms and its derivations as CNNs, with very few parameters. Currently, I am using TensorFlow to do back propagation to train the parameters in these algorithms, instead of manually set them.  These parameters includes the optical parameters and the filter coefficients. We already find that for the focal flow algorithm, trained parameters can result in much better performance in depth prediction than the manually set parameters. And we are making this current work into an ICCV submission. After this, I will move on to jointly train the optical setups and the inference algorithms together.  
